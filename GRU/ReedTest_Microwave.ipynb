{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################\n",
      "Iteration #1\n",
      "##############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\nilm_metadata\\file_management.py:16: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  objs = yaml.load(fh)\n",
      "E:\\WorkSpace\\Python\\Notebooks\\thesis\\NILM-Stacking-master\\NILM-Stacking-master\\GRU\\grudisaggregator.py:113: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(mainlist) == len(meterlist), \"Number of main and meter channels should be equal\")\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 13:07:41.311306 10380 deprecation_wrapper.py:119] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 13:07:41.313323 10380 deprecation_wrapper.py:119] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 13:07:41.317297 10380 deprecation_wrapper.py:119] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 13:07:42.596358 10380 deprecation_wrapper.py:119] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 13:07:44.996383 10380 deprecation.py:323] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0806 13:07:47.687435 10380 deprecation_wrapper.py:119] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0806 13:07:48.301383 10380 deprecation_wrapper.py:119] From C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "83589/83589 [==============================] - 24s 290us/step - loss: 9.1566e-04\n",
      "Epoch 2/4\n",
      "83589/83589 [==============================] - 17s 199us/step - loss: 7.7148e-04\n",
      "Epoch 3/4\n",
      "83589/83589 [==============================] - 16s 197us/step - loss: 7.0903e-04\n",
      "Epoch 4/4\n",
      "83589/83589 [==============================] - 17s 200us/step - loss: 6.9750e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick_\\.conda\\envs\\nilmtk-env2\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sensible chunk: 10124\n",
      "New sensible chunk: 9389\n",
      "New sensible chunk: 7315\n",
      "New sensible chunk: 4508\n",
      "New sensible chunk: 223\n",
      "New sensible chunk: 2794\n",
      "New sensible chunk: 11546\n",
      "New sensible chunk: 2710\n",
      "New sensible chunk: 2273\n",
      "New sensible chunk: 2904\n",
      "New sensible chunk: 8404\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GRUDisaggregator' object has no attribute '_save_metadata_for_disaggregation_custom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac122aa939ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# output: The output datastore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# train_meter: This is used in order to copy the metadata of the train meter into the datastore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mgru\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisaggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_mains\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_elec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'microwave'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mres_elec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\WorkSpace\\Python\\Notebooks\\thesis\\NILM-Stacking-master\\NILM-Stacking-master\\GRU\\grudisaggregator.py\u001b[0m in \u001b[0;36mdisaggregate\u001b[1;34m(self, mains, output_datastore, meter_metadata, **load_kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;31m# Save metadata to output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_is_available\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             self._save_metadata_for_disaggregation_custom(\n\u001b[0m\u001b[0;32m    413\u001b[0m                 \u001b[0moutput_datastore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_datastore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[0msample_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_period'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GRUDisaggregator' object has no attribute '_save_metadata_for_disaggregation_custom'"
     ]
    }
   ],
   "source": [
    "import tables\n",
    "tables.file._open_files.close_all()\n",
    "for i in range(11):\n",
    "    y=i+1\n",
    "    print('##############################################################################')\n",
    "    print('Iteration #{0}'.format(y))\n",
    "    print('##############################################################################')\n",
    "    #training\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    from tensorflow import set_random_seed\n",
    "    set_random_seed(2)\n",
    "    import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "    from nilmtk import DataSet\n",
    "    train = DataSet('redd.h5')\n",
    "    \n",
    "    train.set_window(end=\"30-4-2011\") #Use data only until 4/30/2011\n",
    "    train_elec = train.buildings[1].elec\n",
    "\n",
    "\n",
    "    from grudisaggregator import GRUDisaggregator\n",
    "    gru = GRUDisaggregator()\n",
    "    train_mains = train_elec.mains().all_meters()[0] # The aggregated meter that provides the input\n",
    "    train_meter = train_elec.submeters()['microwave'] # The microwave meter that is used as a training target\n",
    "\n",
    "    gru.train(train_mains, train_meter, epochs=4, sample_period=12)\n",
    "    #gru.export_model(\"model-redd12b.h5\")\n",
    "    \n",
    "    #testing\n",
    "    test = DataSet('redd.h5')\n",
    "    test.set_window(start=\"30-4-2011\")\n",
    "    test_elec = test.buildings[1].elec\n",
    "    test_mains = test_elec.mains().all_meters()[0]\n",
    "    \n",
    "    # dis == The filename of the resulting datastore\n",
    "    x= i+1\n",
    "    str1 = str(x)\n",
    "    str2 = '.h5'\n",
    "    dis  = str1+str2\n",
    "    \n",
    "    #dis = '2.h5' \n",
    "    \n",
    "    from nilmtk.datastore import HDFDataStore\n",
    "    output = HDFDataStore(dis, 'w')\n",
    "\n",
    "    # test_mains: The aggregated signal meter\n",
    "    # output: The output datastore\n",
    "    # train_meter: This is used in order to copy the metadata of the train meter into the datastore\n",
    "    gru.disaggregate(test_mains, output, test_elec['microwave'], sample_period=12)\n",
    "    result = DataSet(dis)\n",
    "    res_elec = result.buildings[1].elec\n",
    "    predicted = res_elec['microwave']\n",
    "    ground_truth = test_elec['microwave']\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    predicted.plot()\n",
    "    ground_truth.plot()\n",
    "    plt.show()\n",
    "    import metrics\n",
    "    rpaf = metrics.recall_precision_accuracy_f1(predicted, ground_truth)\n",
    "    print(\"============ Recall: {}\".format(rpaf[0]))\n",
    "    print(\"============ Precision: {}\".format(rpaf[1]))\n",
    "    print(\"============ Accuracy: {}\".format(rpaf[2]))\n",
    "    print(\"============ F1 Score: {}\".format(rpaf[3]))\n",
    "\n",
    "    print(\"============ Relative error in total energy: {}\".format(metrics.relative_error_total_energy(predicted, ground_truth)))\n",
    "    print(\"============ Mean absolute error(in Watts): {}\".format(metrics.mean_absolute_error(predicted, ground_truth)))\n",
    "    tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
